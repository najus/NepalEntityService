{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Quality Analysis with Nepal Entity Service\n",
    "\n",
    "This notebook demonstrates how to analyze and improve data quality in the Nepal Entity Service (nes2). We'll identify issues, validate data integrity, and generate quality reports.\n",
    "\n",
    "## Topics Covered\n",
    "\n",
    "1. Database statistics and overview\n",
    "2. Identify entities with missing data\n",
    "3. Check for naming inconsistencies\n",
    "4. Validate relationship integrity\n",
    "5. Find orphaned relationships\n",
    "6. Analyze version history patterns\n",
    "7. Generate data quality report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "\n",
    "from nes2.database.file_database import FileDatabase\n",
    "from nes2.services.publication import PublicationService\n",
    "from nes2.services.search import SearchService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize services\n",
    "db_path = Path(\"../nes-db/v2\")\n",
    "db = FileDatabase(base_path=str(db_path))\n",
    "pub_service = PublicationService(database=db)\n",
    "search_service = SearchService(database=db)\n",
    "\n",
    "print(\"✓ Services initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Database Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect database statistics\n",
    "print(\"Collecting database statistics...\\n\")\n",
    "\n",
    "# Count entities by type\n",
    "entity_types = [\"person\", \"organization\", \"location\"]\n",
    "type_counts = {}\n",
    "\n",
    "for entity_type in entity_types:\n",
    "    entities = await db.list_entities(entity_type=entity_type, limit=1000)\n",
    "    type_counts[entity_type] = len(entities)\n",
    "\n",
    "print(\"Entity Counts by Type:\")\n",
    "print(\"=\" * 50)\n",
    "for entity_type, count in type_counts.items():\n",
    "    print(f\"  {entity_type.capitalize()}: {count}\")\n",
    "\n",
    "total_entities = sum(type_counts.values())\n",
    "print(f\"\\n  Total Entities: {total_entities}\")\n",
    "\n",
    "# Count relationships\n",
    "all_relationships = await search_service.search_relationships(limit=1000)\n",
    "print(f\"\\n  Total Relationships: {len(all_relationships)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Identify Entities with Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find entities with incomplete data\n",
    "print(\"Analyzing data completeness...\\n\")\n",
    "\n",
    "issues = {\"missing_nepali_names\": [], \"missing_attributes\": [], \"single_name_only\": []}\n",
    "\n",
    "# Check all entities\n",
    "for entity_type in entity_types:\n",
    "    entities = await db.list_entities(entity_type=entity_type, limit=1000)\n",
    "\n",
    "    for entity in entities:\n",
    "        # Check for Nepali names\n",
    "        has_nepali = any(name.ne and name.ne.full for name in entity.names)\n",
    "        if not has_nepali:\n",
    "            issues[\"missing_nepali_names\"].append(entity.id)\n",
    "\n",
    "        # Check for attributes\n",
    "        if not entity.attributes or len(entity.attributes) == 0:\n",
    "            issues[\"missing_attributes\"].append(entity.id)\n",
    "\n",
    "        # Check for multiple names\n",
    "        if len(entity.names) == 1:\n",
    "            issues[\"single_name_only\"].append(entity.id)\n",
    "\n",
    "print(\"Data Completeness Issues:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"  Missing Nepali names: {len(issues['missing_nepali_names'])}\")\n",
    "print(f\"  Missing attributes: {len(issues['missing_attributes'])}\")\n",
    "print(f\"  Single name only: {len(issues['single_name_only'])}\")\n",
    "\n",
    "# Show examples\n",
    "if issues[\"missing_nepali_names\"]:\n",
    "    print(f\"\\n  Examples (missing Nepali names):\")\n",
    "    for entity_id in issues[\"missing_nepali_names\"][:3]:\n",
    "        entity = await pub_service.get_entity(entity_id)\n",
    "        if entity:\n",
    "            print(f\"    - {entity.names[0].en.full} ({entity.id})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Check Naming Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for naming issues\n",
    "print(\"Checking naming consistency...\\n\")\n",
    "\n",
    "naming_issues = {\"no_primary_name\": [], \"multiple_primary_names\": [], \"empty_names\": []}\n",
    "\n",
    "for entity_type in entity_types:\n",
    "    entities = await db.list_entities(entity_type=entity_type, limit=1000)\n",
    "\n",
    "    for entity in entities:\n",
    "        # Count PRIMARY names\n",
    "        primary_count = sum(1 for name in entity.names if name.kind == \"PRIMARY\")\n",
    "\n",
    "        if primary_count == 0:\n",
    "            naming_issues[\"no_primary_name\"].append(entity.id)\n",
    "        elif primary_count > 1:\n",
    "            naming_issues[\"multiple_primary_names\"].append(entity.id)\n",
    "\n",
    "        # Check for empty names\n",
    "        for name in entity.names:\n",
    "            if not name.en or not name.en.full:\n",
    "                naming_issues[\"empty_names\"].append(entity.id)\n",
    "                break\n",
    "\n",
    "print(\"Naming Consistency Issues:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"  No PRIMARY name: {len(naming_issues['no_primary_name'])}\")\n",
    "print(f\"  Multiple PRIMARY names: {len(naming_issues['multiple_primary_names'])}\")\n",
    "print(f\"  Empty names: {len(naming_issues['empty_names'])}\")\n",
    "\n",
    "if naming_issues[\"multiple_primary_names\"]:\n",
    "    print(f\"\\n  Examples (multiple PRIMARY names):\")\n",
    "    for entity_id in naming_issues[\"multiple_primary_names\"][:3]:\n",
    "        entity = await pub_service.get_entity(entity_id)\n",
    "        if entity:\n",
    "            primary_names = [n.en.full for n in entity.names if n.kind == \"PRIMARY\"]\n",
    "            print(f\"    - {entity.id}: {', '.join(primary_names)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Validate Relationship Integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check relationship integrity\n",
    "print(\"Validating relationship integrity...\\n\")\n",
    "\n",
    "relationship_issues = {\"missing_source\": [], \"missing_target\": [], \"invalid_dates\": []}\n",
    "\n",
    "all_relationships = await search_service.search_relationships(limit=1000)\n",
    "\n",
    "for rel in all_relationships:\n",
    "    # Check if source entity exists\n",
    "    source = await pub_service.get_entity(rel.source_entity_id)\n",
    "    if not source:\n",
    "        relationship_issues[\"missing_source\"].append(rel.id)\n",
    "\n",
    "    # Check if target entity exists\n",
    "    target = await pub_service.get_entity(rel.target_entity_id)\n",
    "    if not target:\n",
    "        relationship_issues[\"missing_target\"].append(rel.id)\n",
    "\n",
    "    # Check date validity\n",
    "    if rel.start_date and rel.end_date:\n",
    "        if rel.end_date < rel.start_date:\n",
    "            relationship_issues[\"invalid_dates\"].append(rel.id)\n",
    "\n",
    "print(\"Relationship Integrity Issues:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"  Missing source entity: {len(relationship_issues['missing_source'])}\")\n",
    "print(f\"  Missing target entity: {len(relationship_issues['missing_target'])}\")\n",
    "print(f\"  Invalid dates: {len(relationship_issues['invalid_dates'])}\")\n",
    "\n",
    "if relationship_issues[\"missing_source\"]:\n",
    "    print(f\"\\n  Orphaned relationships (missing source):\")\n",
    "    for rel_id in relationship_issues[\"missing_source\"][:3]:\n",
    "        print(f\"    - {rel_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Analyze Version History Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze version history\n",
    "print(\"Analyzing version history patterns...\\n\")\n",
    "\n",
    "version_stats = {\n",
    "    \"total_versions\": 0,\n",
    "    \"entities_with_multiple_versions\": 0,\n",
    "    \"max_versions\": 0,\n",
    "    \"authors\": defaultdict(int),\n",
    "}\n",
    "\n",
    "# Sample entities for version analysis\n",
    "sample_entities = await db.list_entities(limit=50)\n",
    "\n",
    "for entity in sample_entities:\n",
    "    versions = await pub_service.get_entity_versions(entity.id)\n",
    "    version_count = len(versions)\n",
    "\n",
    "    version_stats[\"total_versions\"] += version_count\n",
    "\n",
    "    if version_count > 1:\n",
    "        version_stats[\"entities_with_multiple_versions\"] += 1\n",
    "\n",
    "    if version_count > version_stats[\"max_versions\"]:\n",
    "        version_stats[\"max_versions\"] = version_count\n",
    "\n",
    "    # Count by author\n",
    "    for version in versions:\n",
    "        version_stats[\"authors\"][version.author.slug] += 1\n",
    "\n",
    "print(\"Version History Statistics:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"  Total versions (sample): {version_stats['total_versions']}\")\n",
    "print(\n",
    "    f\"  Entities with multiple versions: {version_stats['entities_with_multiple_versions']}\"\n",
    ")\n",
    "print(f\"  Maximum versions for single entity: {version_stats['max_versions']}\")\n",
    "\n",
    "print(f\"\\n  Changes by author:\")\n",
    "for author, count in sorted(\n",
    "    version_stats[\"authors\"].items(), key=lambda x: x[1], reverse=True\n",
    "):\n",
    "    print(f\"    - {author}: {count} change(s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Generate Data Quality Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive quality report\n",
    "print(\"=\" * 70)\n",
    "print(\"DATA QUALITY REPORT\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nGenerated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Database: {db_path}\")\n",
    "\n",
    "print(f\"\\n1. DATABASE OVERVIEW\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"  Total Entities: {total_entities}\")\n",
    "for entity_type, count in type_counts.items():\n",
    "    print(f\"    - {entity_type.capitalize()}: {count}\")\n",
    "print(f\"  Total Relationships: {len(all_relationships)}\")\n",
    "\n",
    "print(f\"\\n2. DATA COMPLETENESS\")\n",
    "print(\"-\" * 70)\n",
    "completeness_score = 100\n",
    "if total_entities > 0:\n",
    "    missing_nepali_pct = (len(issues[\"missing_nepali_names\"]) / total_entities) * 100\n",
    "    missing_attrs_pct = (len(issues[\"missing_attributes\"]) / total_entities) * 100\n",
    "    completeness_score = 100 - (missing_nepali_pct + missing_attrs_pct) / 2\n",
    "\n",
    "print(f\"  Completeness Score: {completeness_score:.1f}%\")\n",
    "print(\n",
    "    f\"  Missing Nepali names: {len(issues['missing_nepali_names'])} ({missing_nepali_pct:.1f}%)\"\n",
    ")\n",
    "print(\n",
    "    f\"  Missing attributes: {len(issues['missing_attributes'])} ({missing_attrs_pct:.1f}%)\"\n",
    ")\n",
    "\n",
    "print(f\"\\n3. NAMING CONSISTENCY\")\n",
    "print(\"-\" * 70)\n",
    "naming_score = 100\n",
    "if total_entities > 0:\n",
    "    naming_issues_count = sum(len(v) for v in naming_issues.values())\n",
    "    naming_score = max(0, 100 - (naming_issues_count / total_entities) * 100)\n",
    "\n",
    "print(f\"  Naming Score: {naming_score:.1f}%\")\n",
    "print(f\"  No PRIMARY name: {len(naming_issues['no_primary_name'])}\")\n",
    "print(f\"  Multiple PRIMARY names: {len(naming_issues['multiple_primary_names'])}\")\n",
    "print(f\"  Empty names: {len(naming_issues['empty_names'])}\")\n",
    "\n",
    "print(f\"\\n4. RELATIONSHIP INTEGRITY\")\n",
    "print(\"-\" * 70)\n",
    "integrity_score = 100\n",
    "if len(all_relationships) > 0:\n",
    "    integrity_issues_count = sum(len(v) for v in relationship_issues.values())\n",
    "    integrity_score = max(\n",
    "        0, 100 - (integrity_issues_count / len(all_relationships)) * 100\n",
    "    )\n",
    "\n",
    "print(f\"  Integrity Score: {integrity_score:.1f}%\")\n",
    "print(f\"  Missing source: {len(relationship_issues['missing_source'])}\")\n",
    "print(f\"  Missing target: {len(relationship_issues['missing_target'])}\")\n",
    "print(f\"  Invalid dates: {len(relationship_issues['invalid_dates'])}\")\n",
    "\n",
    "print(f\"\\n5. OVERALL QUALITY SCORE\")\n",
    "print(\"-\" * 70)\n",
    "overall_score = (completeness_score + naming_score + integrity_score) / 3\n",
    "print(f\"  Overall Score: {overall_score:.1f}%\")\n",
    "\n",
    "if overall_score >= 90:\n",
    "    grade = \"A (Excellent)\"\n",
    "elif overall_score >= 80:\n",
    "    grade = \"B (Good)\"\n",
    "elif overall_score >= 70:\n",
    "    grade = \"C (Fair)\"\n",
    "elif overall_score >= 60:\n",
    "    grade = \"D (Poor)\"\n",
    "else:\n",
    "    grade = \"F (Critical)\"\n",
    "\n",
    "print(f\"  Grade: {grade}\")\n",
    "\n",
    "print(f\"\\n6. RECOMMENDATIONS\")\n",
    "print(\"-\" * 70)\n",
    "if len(issues[\"missing_nepali_names\"]) > 0:\n",
    "    print(f\"  • Add Nepali names to {len(issues['missing_nepali_names'])} entities\")\n",
    "if len(issues[\"missing_attributes\"]) > 0:\n",
    "    print(f\"  • Add attributes to {len(issues['missing_attributes'])} entities\")\n",
    "if len(naming_issues[\"multiple_primary_names\"]) > 0:\n",
    "    print(\n",
    "        f\"  • Fix {len(naming_issues['multiple_primary_names'])} entities with multiple PRIMARY names\"\n",
    "    )\n",
    "if (\n",
    "    len(relationship_issues[\"missing_source\"]) > 0\n",
    "    or len(relationship_issues[\"missing_target\"]) > 0\n",
    "):\n",
    "    print(f\"  • Clean up orphaned relationships\")\n",
    "if overall_score >= 90:\n",
    "    print(f\"  • Data quality is excellent! Continue maintaining high standards.\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary\n",
    "\n",
    "In this notebook, we've performed comprehensive data quality analysis:\n",
    "\n",
    "- ✓ Collected database statistics\n",
    "- ✓ Identified entities with missing data\n",
    "- ✓ Checked naming consistency\n",
    "- ✓ Validated relationship integrity\n",
    "- ✓ Analyzed version history patterns\n",
    "- ✓ Generated data quality report with scores\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. Address identified data quality issues\n",
    "2. Set up regular quality monitoring\n",
    "3. Create automated quality checks\n",
    "4. Document data quality standards\n",
    "\n",
    "### Resources\n",
    "\n",
    "- Data Maintainer Guide: `docs/data-maintainer-guide.md`\n",
    "- Example Scripts: `examples/`\n",
    "- API Documentation: Run the server and visit `/docs`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
